{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this excerise we will try to predict if a customer will subscribe to a term deposit , when is called from a call center.\n",
    "The details of the dataset can be found here. [Portugese bank marketing dataset](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Input variables:\n",
    "#### Bank client data:\n",
    "1 - age (numeric)\n",
    "\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "#### Related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "#### Other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "\n",
    "#### Social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "plt.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read the dataset & drop columns with NA values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/org_banking.txt', header=0)\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data conversion.\n",
    "We will convert basic education of different types into one type.This should reduce the cardinality of `education` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['education']=np.where(data['education'] =='basic.9y', 'basic', data['education'])\n",
    "data['education']=np.where(data['education'] =='basic.6y', 'basic', data['education'])\n",
    "data['education']=np.where(data['education'] =='basic.4y', 'basic', data['education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_no_sub = len(data[data['y']==0])\n",
    "count_sub = len(data[data['y']==1])\n",
    "pct_of_no_sub = count_no_sub/(count_no_sub+count_sub)\n",
    "print(\"Percentage of no subscription is\", pct_of_no_sub*100)\n",
    "pct_of_sub = count_sub/(count_no_sub+count_sub)\n",
    "print(\"Percentage of subscription\", pct_of_sub*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Quick preview of the data.\n",
    "The data that we have indeed has a lot of string values and we will have to convert them to numreical values.\n",
    "This can be done using Onehotencoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Remove co-linear features\n",
    "It is always a good idea to remove the co-linear feautures. The following code snippet removes co-linear features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = data.corr().abs()\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "# Drop features \n",
    "data.drop(data[to_drop], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Split the data in test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.y.values\n",
    "X_df = data.drop(columns=['y'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encodings\n",
    "There are two popular ways to do this: label encoding and one hot encoding.\n",
    "\n",
    "For label encoding, a different number is assigned to each unique value in the feature column. A potential issue with this method would be the assumption that the label sizes represent ordinality (i.e. a label of 3 is greater than a label of 1).\n",
    "\n",
    "For one hot encoding, a new feature column is created for each unique value in the feature column. The value would be 1 if the value was present for that observation and 0 otherwise. \n",
    "This method however could easily lead to an explosion in number of features and lead to the curse of dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode categorical variables.\n",
    "label_encoder = LabelEncoder()\n",
    "mappings = []\n",
    "\n",
    "# Desired label orders for categorical columns.\n",
    "educ_order = ['unknown', 'illiterate','basic', 'high.school', 'professional.course', 'university.degree']\n",
    "month_order = ['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "day_order = ['mon', 'tue', 'wed', 'thu', 'fri']\n",
    "\n",
    "# using cat.codes for order, one hot for high cardinality and weak case of cardinality.\n",
    "def ordered_labels(df, col, order):\n",
    "    df[col] = df[col].astype('category')\n",
    "    df[col] = df[col].cat.reorder_categories(order, ordered=True)\n",
    "    df[col] = df[col].cat.codes.astype(int)\n",
    "\n",
    "# Use dummy variables for occupation\n",
    "X_df = pd.concat([X_df, pd.get_dummies(X_df['job'])],axis=1).drop('job',axis=1)\n",
    "\n",
    "# Use ordered cat.codes for days, months, and education\n",
    "ordered_labels(X_df, 'education', educ_order)\n",
    "ordered_labels(X_df, 'month', month_order)\n",
    "ordered_labels(X_df, 'day_of_week', day_order)\n",
    "\n",
    "# Same label encoding for rest since low cardinality\n",
    "for i, col in enumerate(X_df):\n",
    "    #If the data is of type string,apply LabelEncoding\n",
    "    if X_df[col].dtype == 'object':\n",
    "        X_df[col] = label_encoder.fit_transform(np.array(X_df[col].astype(str)).reshape((-1,)))\n",
    "        mappings.append(dict(zip(label_encoder.classes_, range(1, len(label_encoder.classes_)+1))))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train a Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Logistic Regression:\n",
    "from sklearn.metrics import plot_roc_curve,roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler,MaxAbsScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "lr_scaler = StandardScaler()\n",
    "lr_clf = LogisticRegression(max_iter=2500)\n",
    "\n",
    "pipeline = Pipeline([('scaler',lr_scaler),('classifier',lr_clf)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(f'Logistic regression train AUC  :{roc_auc_score(y_train,pipeline.predict_proba(X_train)[:,1])}')\n",
    "print(f'Logistic regression test AUC  :{roc_auc_score(y_test,pipeline.predict_proba(X_test)[:,1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Tune a Logisitic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create param grid.\n",
    "param_grid = [\n",
    "    {\n",
    "    'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.arange(1,10,0.5),\n",
    "    'classifier__solver' : ['liblinear'] },\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "clf = GridSearchCV(pipeline, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "# Take the best estimator and fit on entire training data\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Logistic regression train AUC  :{roc_auc_score(y_train,best_clf.best_estimator_.predict_proba(X_train)[:,1])}')\n",
    "print(f'Logistic regression test AUC  :{roc_auc_score(y_test,best_clf.best_estimator_.predict_proba(X_test)[:,1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Train a RandomForestClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=10,random_state=73)\n",
    "# Creae a pipeline.\n",
    "rf_pipeline = Pipeline([('classifier',lr_clf)])\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(f'RF regression train AUC  :{roc_auc_score(y_train,rf_pipeline.predict_proba(X_train)[:,1])}')\n",
    "print(f'RF regression test AUC  :{roc_auc_score(y_test,rf_pipeline.predict_proba(X_test)[:,1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excersise\n",
    "Tune a RF model. Does it perform better or worse than the Linear Model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('classifier',RandomForestClassifier())])\n",
    "\n",
    "# Create param grid.\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "# Fit on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC AUC score on Training and Test data .\n",
    "print(f'RF regression train AUC  :{roc_auc_score(y_train,best_clf.best_estimator_.predict_proba(X_train)[:,1])}')\n",
    "print(f'RF regression test AUC  :{roc_auc_score(y_test,best_clf.best_estimator_.predict_proba(X_test)[:,1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
